{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf5bQw9lZTzN"
   },
   "source": [
    "# Exercise on data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space to load some standard libraries \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf5bQw9lZTzN"
   },
   "source": [
    "## 1 Loading the data \n",
    "The data set for this tutorial comes from the classic Book Credit Scoring and its Applications by Lyn C. Thomas, David B. Edelman, and Jonathan N. Crook. There is  also a file *loan_data_dictionary*, which offers a brief description of the features in this data set. In a nutshell, the data represents yet another vanilla credit scoring task with a binary target variable, indicating whether bank customers repaid their debt or defaulted, and a few features characterizing credit applicants. Your first task is to load the data into a `Pandas DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54Ud3XtqZTzN"
   },
   "outputs": [],
   "source": [
    "# Load the data \n",
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlHauiUhZTzO"
   },
   "source": [
    "By now, you have run through the process of getting a first idea about a new data set many times. Now take a quick look into the data yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSvtKE1hZTzO"
   },
   "outputs": [],
   "source": [
    "# Some space for any code you want to write to take a first look\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86a0L4iMZTzO"
   },
   "source": [
    "## 2 Data types\n",
    "You can tell from the data dictionary that the loan data includes numeric and categorical variables. Draw on the examples from the data preprocessing notebook and make sure that all numeric features are stored as `float32` and all categorical features are stored as categories in your DataFame. Also, ensure that the feature `PHON` is stored as a boolean. Finally pick a suitable data type for the target variable `BAD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of BAD\n",
    "\n",
    "# Conversion of PHON\n",
    "\n",
    "# Handling of the categorical features\n",
    "\n",
    "# Handling of the numerical features\n",
    "\n",
    "# Verify success of your changes \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBHdKZhVZTzO"
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "### 3.1 Histogram\n",
    "The data includes a feature dINC_A, which captures the income of a credit applicant. We would expect that this feature is related to our target variable, which is called BAD in the data set. \n",
    "\n",
    "Create a histogram plot of the income feature and examine its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOrcl7obZTzO"
   },
   "outputs": [],
   "source": [
    "# Histogram of dINC_A \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA2E41Q-ZTzO"
   },
   "source": [
    "The distribution reveals some potentially important insights. However, the histogram alone does not suffice to check our intuition that income and credit risk are related. Let's examine the income distribution across good and bad credit applications.\n",
    "\n",
    "### 3.2 Analysis of the dependency between applicants' income and credit risk\n",
    "We begin with a manual approach, which also allows us to revisit logical indexing in Python and Pandas. Calculate the average income of a credit applicant for good risks and for bad risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozLSHlVOZTzO"
   },
   "outputs": [],
   "source": [
    "# Calculate the group-wise mean of dINC_A for good and bad risks using logical indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BGB_zEbZTzO"
   },
   "source": [
    "Remember that the Pandas function `groupby()` allows you to perform an analysis similar to your above calculation of the group-wise means. Replicate the previous calculation using `groupby()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hw0DEqzbZTzO"
   },
   "outputs": [],
   "source": [
    "# Replicate previous results using groupby()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX1sCedMZTzO"
   },
   "source": [
    "Next, we perform a graphical analysis. Depict the distribution of the income of customers with a good and bad risk, respectively, by means of a box-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0InCH1Z_ZTzP"
   },
   "outputs": [],
   "source": [
    "# Box plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoStoQjjZTzP"
   },
   "source": [
    "### 3.3 Categorical variables\n",
    "The data set comprises three categorical features. The feature PHON is binary and will not cause any issues. The features EMPS_A and RES are more interesting. Remember to check the data dictionary to understand what information the features encode. \n",
    "\n",
    "In the lecture, we explained that categorical features are typically encoded using dummy variables prior to applying an analytical model. Python supports dummy coding in several ways.  Pandas offers a function `get_dummies()` and sklearn offer a class `OneHotEncoder()`. The Pandas approach is maybe a bit easier to use. The more prevalent approach in practice is to rely on sklearn. \n",
    "\n",
    "Check the documentation of one or both of the above functions. Then create dummy variables for the feature RES and add them to your DataFrame.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGRN72W0ZTzP"
   },
   "outputs": [],
   "source": [
    "# Dummy coding of RES\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_ex_data_prep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:cs330] *",
   "language": "python",
   "name": "conda-env-cs330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
